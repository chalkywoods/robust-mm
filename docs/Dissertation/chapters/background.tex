\chapter{Background}

Machine learning has been used over a wide range of tasks including computer vision, recommendation, medical diagnosis and human activity recognition. Shallow methods such as Random Forest and Support Vector Machines have been superseded by deep learning techniques as computational power availability has increased. Various additions to the basic feed-forward neural network have been made to better take advantage of spatial and temporal relationships between features in data sources such as images, audio and video streams, and real time sensor data.\\

A Convolutional Neural Network (CNN) \cite{Neocognitron} uses convolutional layers to identify spatial or temporal features. Each layer learns a number of kernels with small receptive field which are convolved over the input to produce an activation map. Kernels represent features in the input, e.g a 2D kernel in an image could represent a vertical line, with its activation map showing the location of all vertical lines in the image. Stacking multiple convolutional layers identifies more complex, larger scale spacial features in the input in the same way as the human eye. CNNs can also identify temporal features by stacking sequential frames of data and applying kernels over the temporal dimension.\\

State of the art image classifiers have achieved high accuracy with CNNs on general image recognition datasets such as ImageNet. One drawback of CNNs is the relatively large storage and computational requirements needed to use them during both training and inference.\\

Another method of identifying temporal features is with a Recurrent Neural Network (RNN). Recurrent layers contain cells which receive their output from the previous forward pass as an additional input. This allows information to flow through the network temporally, and features can be identified over multiple time steps.\\

An extension of this, as used in \cite{DeepConvLSTM}, is the Long Short Term Memory unit (LSTM) \cite{LSTM}. An LSTM consists of the cell itself and input, forget and output gates, controlling flow of information. These gates allow values into the cell, to remain in the cell, and to flow out of the cell via the activation function, respectively. Although basic recurrent cells can theoretically learn features over arbitrary timescales, finite-precision arithmetic used in computation makes identifying long term features difficult during training. LSTM cells do not suffer from the same issues and are therefore better suited to learning over longer timescales.\\

Proposed multimodal architectures tend to differ on how early or late data from different modalities are brought together, known as sensor fusion \cite{RaduMultimodal}. On one extreme is Ensemble Classification, where a classification for each modality is obtained using an appropriate classifier. The results of these separate classifiers are used with a majority voting scheme for the final classification. The other extreme is Feature Concatenation, where features from all modalities are concatenated into a single vector used for classification. This has the advantage of being able to learn cross-modality relationships, but can hinder learning of intra-modality relationships.\\

A split multimodal network architecture \cite{RaduMultimodal} has been found to have better results than architectures that have early or late fusion. A small network for each modality is used to generate a set of features. These are then concatenated and fed into a further combined network. The modality specific networks allow the model to learn intra-modality relationships before being fused with the other modalities to learn cross modality relationships. Modout \cite{modout} is capable of learning when to share information between modalities during training.\\

Implementations often assume that the multimodal data supplied to the model is complete and clean. However, in real world conditions data from a particular modality or sensor may be corrupted or completely missing, resulting in inaccurate results from such a model. Methods of detecting or mitigating data modality corruption are discussed in the following section.\\
